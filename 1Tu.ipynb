{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# define the path to the TuSimple dataset\n",
    "data_dir = 'D:/Data/TUSimple/clips/'\n",
    "\n",
    "# function to read the training data and annotations\n",
    "def read_training_data(data_dir):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # iterate over the training data\n",
    "    for i in range(1, 3617):\n",
    "        # read the image file\n",
    "        img_file = f\"{data_dir}/clips/0531/{i:04d}/img/0000.jpg\"\n",
    "        img = np.array(Image.open(img_file))\n",
    "\n",
    "        # read the annotation file\n",
    "        annotation_file = f\"{data_dir}/clips/0531/{i:04d}/anno/0000.json\"\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            annotation = json.load(f)\n",
    "\n",
    "        # extract the lane markings from the annotation\n",
    "        lane_markings = np.zeros_like(img[:,:,0])\n",
    "        for lane in annotation['lanes']:\n",
    "            if lane:\n",
    "                lane_points = np.array(lane)\n",
    "                lane_points = np.transpose(np.vstack((lane_points, np.arange(len(lane_points)))))\n",
    "                lane_points = lane_points[np.all(lane_points > 0, axis=1)]\n",
    "                lane_points = lane_points[np.all(lane_points < np.array(img.shape[:2]).reshape(1,2), axis=1)]\n",
    "                lane_points = lane_points.astype(np.int32)\n",
    "                lane_markings[lane_points[:, 1], lane_points[:, 0]] = 1\n",
    "\n",
    "        # append the image and label to the training data\n",
    "        X.append(img)\n",
    "        Y.append(lane_markings)\n",
    "\n",
    "    # convert the training data to numpy arrays\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# function to normalize the training data\n",
    "def normalize(X):\n",
    "    X = X / 255.0\n",
    "    X = X.astype(np.float32)\n",
    "    return X\n",
    "\n",
    "# function to perform data augmentation\n",
    "def augment(X, Y):\n",
    "    # flip the images horizontally\n",
    "    X_flip = np.flip(X, axis=2)\n",
    "    Y_flip = np.flip(Y, axis=2)\n",
    "\n",
    "    # concatenate the original and flipped images\n",
    "    X_aug = np.concatenate((X, X_flip), axis=0)\n",
    "    Y_aug = np.concatenate((Y, Y_flip), axis=0)\n",
    "\n",
    "    return X_aug, Y_aug\n",
    "\n",
    "# function to load the data\n",
    "def load_data():\n",
    "    # read the training data and annotations\n",
    "    X_train, Y_train = read_training_data(data_dir)\n",
    "\n",
    "    # normalize the training data\n",
    "    X_train = normalize(X_train)\n",
    "\n",
    "    # perform data augmentation\n",
    "    X_train, Y_train = augment(X_train, Y_train)\n",
    "\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Data/TUSimple/clips//clips/0531/0001/img/0000.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m read_training_data(data_dir)\n",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m, in \u001b[0;36mread_training_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m3617\u001b[39m):\n\u001b[0;32m     15\u001b[0m     \u001b[39m# read the image file\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     img_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdata_dir\u001b[39m}\u001b[39;00m\u001b[39m/clips/0531/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m04d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/img/0000.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39;49mopen(img_file))\n\u001b[0;32m     19\u001b[0m     \u001b[39m# read the annotation file\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     annotation_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdata_dir\u001b[39m}\u001b[39;00m\u001b[39m/clips/0531/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m04d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/anno/0000.json\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Data/TUSimple/clips//clips/0531/0001/img/0000.jpg'"
     ]
    }
   ],
   "source": [
    "read_training_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "TRAIN_SET = ['label_data_0313.json', 'label_data_0601.json']\n",
    "VAL_SET = ['label_data_0531.json']\n",
    "TRAIN_VAL_SET = TRAIN_SET + VAL_SET\n",
    "TEST_SET = ['test_label.json']\n",
    "\n",
    "def gen_label_for_json(args, image_set):\n",
    "    H, W = 720, 1280\n",
    "    SEG_WIDTH = 30\n",
    "    save_dir = args.savedir\n",
    "\n",
    "    os.makedirs(os.path.join(args.root, args.savedir, \"list\"), exist_ok=True)\n",
    "    list_f = open(os.path.join(args.root, args.savedir, \"list\", \"{}_gt.txt\".format(image_set)), \"w\")\n",
    "\n",
    "    json_path = os.path.join(args.root, args.savedir, \"{}.json\".format(image_set))\n",
    "    with open(json_path) as f:\n",
    "        for line in f:\n",
    "            label = json.loads(line)\n",
    "            # ---------- clean and sort lanes -------------\n",
    "            lanes = []\n",
    "            _lanes = []\n",
    "            slope = [] # identify 0th, 1st, 2nd, 3rd, 4th, 5th lane through slope\n",
    "            for i in range(len(label['lanes'])):\n",
    "                l = [(x, y) for x, y in zip(label['lanes'][i], label['h_samples']) if x >= 0]\n",
    "                if (len(l)>1):\n",
    "                    _lanes.append(l)\n",
    "                    slope.append(np.arctan2(l[-1][1]-l[0][1], l[0][0]-l[-1][0]) / np.pi * 180)\n",
    "            _lanes = [_lanes[i] for i in np.argsort(slope)]\n",
    "            slope = [slope[i] for i in np.argsort(slope)]\n",
    "\n",
    "            idx = [None for i in range(6)]\n",
    "            for i in range(len(slope)):\n",
    "                if slope[i] <= 90:\n",
    "                    idx[2] = i\n",
    "                    idx[1] = i-1 if i > 0 else None\n",
    "                    idx[0] = i-2 if i > 1 else None\n",
    "                else:\n",
    "                    idx[3] = i\n",
    "                    idx[4] = i+1 if i+1 < len(slope) else None\n",
    "                    idx[5] = i+2 if i+2 < len(slope) else None\n",
    "                    break\n",
    "            for i in range(6):\n",
    "                lanes.append([] if idx[i] is None else _lanes[idx[i]])\n",
    "\n",
    "            # ---------------------------------------------\n",
    "\n",
    "            img_path = label['raw_file']\n",
    "            seg_img = np.zeros((H, W, 3))\n",
    "            list_str = []  # str to be written to list.txt\n",
    "            for i in range(len(lanes)):\n",
    "                coords = lanes[i]\n",
    "                if len(coords) < 4:\n",
    "                    list_str.append('0')\n",
    "                    continue\n",
    "                for j in range(len(coords)-1):\n",
    "                    cv2.line(seg_img, coords[j], coords[j+1], (i+1, i+1, i+1), SEG_WIDTH//2)\n",
    "                list_str.append('1')\n",
    "\n",
    "            seg_path = img_path.split(\"/\")\n",
    "            seg_path, img_name = os.path.join(args.root, args.savedir, seg_path[1], seg_path[2]), seg_path[3]\n",
    "            os.makedirs(seg_path, exist_ok=True)\n",
    "            seg_path = os.path.join(seg_path, img_name[:-3]+\"png\")\n",
    "            cv2.imwrite(seg_path, seg_img)\n",
    "\n",
    "            seg_path = \"/\".join([args.savedir, *img_path.split(\"/\")[1:3], img_name[:-3]+\"png\"])\n",
    "            if seg_path[0] != '/':\n",
    "                seg_path = '/' + seg_path\n",
    "            if img_path[0] != '/':\n",
    "                img_path = '/' + img_path\n",
    "            list_str.insert(0, seg_path)\n",
    "            list_str.insert(0, img_path)\n",
    "            list_str = \" \".join(list_str) + \"\\n\"\n",
    "            list_f.write(list_str)\n",
    "\n",
    "\n",
    "def generate_json_file(save_dir, json_file, image_set):\n",
    "    with open(os.path.join(save_dir, json_file), \"w\") as outfile:\n",
    "        for json_name in (image_set):\n",
    "            with open(os.path.join(args.root, json_name)) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "\n",
    "def generate_label(args):\n",
    "    save_dir = \"D:/Data/TUSimple/Labels\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    generate_json_file(save_dir, \"train_val.json\", TRAIN_VAL_SET)\n",
    "    generate_json_file(save_dir, \"test.json\", TEST_SET)\n",
    "\n",
    "    print(\"generating train_val set...\")\n",
    "    gen_label_for_json(args, 'train_val')\n",
    "    print(\"generating test set...\")\n",
    "    gen_label_for_json(args, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data_dir = 'D:/Data/TUSimple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:/Data/TUSimple\\\\clips\\\\0313-1\\\\img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m clip \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39mclips\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mfor\u001b[39;00m img_folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_dir, \u001b[39m'\u001b[39;49m\u001b[39mclips\u001b[39;49m\u001b[39m'\u001b[39;49m, clip, \u001b[39m'\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m'\u001b[39;49m)):\n\u001b[0;32m      3\u001b[0m         img_folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39m'\u001b[39m\u001b[39mclips\u001b[39m\u001b[39m'\u001b[39m, clip, \u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m, img_folder)\n\u001b[0;32m      4\u001b[0m         \u001b[39mfor\u001b[39;00m img_file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(img_folder_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:/Data/TUSimple\\\\clips\\\\0313-1\\\\img'"
     ]
    }
   ],
   "source": [
    "for clip in os.listdir(os.path.join(data_dir, 'clips')):#access ../clips clip=imgfloder\n",
    "    for img_folder in os.listdir(os.path.join(data_dir, 'clips', clip)): #../clips/imgfloder\n",
    "        img_folder_path = os.path.join(data_dir, 'clips', clip, img_folder)\n",
    "        for img_file in os.listdir(img_folder_path):\n",
    "            img_path = os.path.join(img_folder_path, img_file)\n",
    "\n",
    "            # create a new annotation dictionary\n",
    "            annotation = {}\n",
    "            annotation['lanes'] = []\n",
    "\n",
    "            # write the annotation file\n",
    "            annotation_file = os.path.join(data_dir, 'clips', clip, 'anno', img_folder, img_file.replace('.jpg', '.json'))\n",
    "            with open(annotation_file, 'w') as f:\n",
    "                json.dump(annotation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trailing data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39mD:/Data/TUSimple/label_data_0313.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\io\\json\\_json.py:757\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    756\u001b[0m \u001b[39mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\io\\json\\_json.py:915\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    914\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    917\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\io\\json\\_json.py:937\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    935\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 937\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m    939\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1064\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_numpy()\n\u001b[0;32m   1063\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_no_numpy()\n\u001b[0;32m   1066\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python-main\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1321\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1317\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[0;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1321\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m     )\n\u001b[0;32m   1323\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1324\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[0;32m   1325\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[0;32m   1326\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1327\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Trailing data"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"D:/Data/TUSimple/label_data_0313.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
